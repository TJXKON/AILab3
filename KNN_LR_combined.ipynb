{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b30daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae59fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"cases_malaysia.csv\") #Get the data from the cases_malaysia.csv\n",
    "data #view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d4c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape #Find the dimension of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec3fc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[(data['date'] >= '2022-01-01') & (data['date'] <= '2022-06-30')] # Find the data range from 1st Jan 2022 to 30th June 2022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3455b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['date'] >= '2022-01-01') & (data['date'] <= '2022-06-30')].sum() # adds the items of an iterable and returns the sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4f45b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['date'] >= '2022-01-01') & (data['date'] <= '2022-06-30')].shape #Find the dimension of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6408b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data[(data['date'] >= '2022-01-01') & (data['date'] <= '2022-06-30')] #set the data to data_new for further step (correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new # Check the data value and compare result with data (no different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d44c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a correlation graph to observe the correlation of data\n",
    "plt.figure(figsize=(35,35))\n",
    "cor = data_new.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.PiYG, vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60876248",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_Users = len(data_new) #Find total users\n",
    "print('There are', Total_Users,'total users')\n",
    "data_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77516d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data by the date from Jan to June 2022\n",
    "data_date_6months = data_new.groupby('date', as_index=False).sum()\n",
    "data_date_6months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160acbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes from combined data for each month (January, Februrary, March, April, May, June)\n",
    "data_date_jan = data_date_6months[(data_date_6months['date'] >= '2022-01-01') & (data_date_6months['date'] <= '2022-01-31')]\n",
    "data_date_feb = data_date_6months[(data_date_6months['date'] >= '2022-02-01') & (data_date_6months['date'] <= '2022-02-28')]    \n",
    "data_date_mar = data_date_6months[(data_date_6months['date'] >= '2022-03-01') & (data_date_6months['date'] <= '2022-03-31')]\n",
    "data_date_apr = data_date_6months[(data_date_6months['date'] >= '2022-04-01') & (data_date_6months['date'] <= '2022-04-30')]\n",
    "data_date_may = data_date_6months[(data_date_6months['date'] >= '2022-05-01') & (data_date_6months['date'] <= '2022-05-31')]\n",
    "data_date_jun = data_date_6months[(data_date_6months['date'] >= '2022-06-01') & (data_date_6months['date'] <= '2022-06-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c93213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns for Jan\n",
    "data_jan_temp = data_date_jan\n",
    "data_jan_temp['date'] = 1\n",
    "data_jan = data_jan_temp.groupby('date', as_index=False).sum()\n",
    "\n",
    "# Find columns for Feb\n",
    "data_feb_temp = data_date_feb\n",
    "data_feb_temp['date'] = 2\n",
    "data_feb = data_feb_temp.groupby('date', as_index=False).sum()\n",
    "\n",
    "# Find columns for Mar\n",
    "data_mar_temp = data_date_mar\n",
    "data_mar_temp['date'] = 3\n",
    "data_mar = data_mar_temp.groupby('date', as_index=False).sum()\n",
    "\n",
    "# Find columns for April\n",
    "data_apr_temp = data_date_apr\n",
    "data_apr_temp['date'] = 4\n",
    "data_apr = data_apr_temp.groupby('date', as_index=False).sum()\n",
    "\n",
    "# Find columns for May\n",
    "data_may_temp = data_date_may\n",
    "data_may_temp['date'] = 5\n",
    "data_may = data_may_temp.groupby('date', as_index=False).sum()\n",
    "\n",
    "# Find columns for Jun\n",
    "data_jun_temp = data_date_jun\n",
    "data_jun_temp['date'] = 6\n",
    "data_jun = data_jun_temp.groupby('date', as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a0b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the items for each months (1 month per row)\n",
    "# This is to compare the total with the data by dates (181)\n",
    "# To ensure no difference in total cases\n",
    "data_6months = pd.concat([data_jan, data_feb, data_mar, data_apr, data_may, data_jun], ignore_index=True)\n",
    "data_6months.rename(columns = {'date':'month'}, inplace = True)\n",
    "data_6months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf734b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a correlation graph by date over the 181 days (January to June 2022)\n",
    "plt.figure(figsize=(35,35))\n",
    "cor = data_date_6months.corr() \n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.PiYG, vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ced87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a correlation graph by month (January to June 2022)\n",
    "plt.figure(figsize=(25,25))\n",
    "cor = data_6months.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.PiYG, vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b39800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding details of the dataset (by date) of the 181 days (January to June 2022 )\n",
    "data_date_6months.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab97be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete date from data_181 (date is not required in the KNN supervised learning)\n",
    "data_181 = data_date_6months.drop([\"date\"], axis=1)\n",
    "data_181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c650ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-nearest neighbors requires scaled data.\n",
    "# The data is scaled using one of the scaling methods. (0 or 1)\n",
    "msc = MinMaxScaler()\n",
    "data_181 = pd.DataFrame(msc.fit_transform(data_181), # this is an np.array, not aâ£,â†’dataframe.\n",
    "                    columns=data_181.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84bbd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the columns that don't contain the label\n",
    "x_cols = [x for x in data_181.columns if x != 'cases_active'] # For this case, cases_active will be our target. Rest is features\n",
    "# Split the data into two dataframes\n",
    "x_data = data_181[x_cols] #Features\n",
    "y_data = data_181['cases_active'] #Target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=42) #Do cross validation 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3aec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find probability \n",
    "np.mean(y_data), np.mean(1-y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550925a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor #Use regressor as our target is continuous \n",
    "start_time = time.time()\n",
    "\n",
    "# randomize the k-neighbors parameter of the knn algorithm\n",
    "param = {'n_neighbors': np.arange(1,20)}\n",
    "\n",
    "# use knn algorithm\n",
    "knn = KNeighborsRegressor() #to predict the value of the output variable by using a local average\n",
    "\n",
    "# use Grid search cv to find the best parameter\n",
    "knn_cv = GridSearchCV(knn, param, cv = 5)\n",
    "# fit the algorithm\n",
    "knn_cv.fit(x_train, y_train)\n",
    "# get the best params and best score results\n",
    "print(\"Best K-neighbor: \" , knn_cv.best_params_)\n",
    "print(\"Best score achieved: \" , knn_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e9b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the accuracy score\n",
    "y_pred = knn_cv.predict(x_test)\n",
    "score = knn_cv.score(x_test, y_test)\n",
    "\n",
    "def accuracy(real, predict):\n",
    "    return sum(y_data == y_pred) / float(real.shape[0])\n",
    "\n",
    "print(\"Accuracy score of y_pred:\", score)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d707ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the K-nearest neighbors model with different values of k (from 1 to 21)\n",
    "# Store the accuracy measurement for each k\n",
    "score_list = list()\n",
    "for k in range(1, 21): #The range can be choose, in this case 1 to 21, k=20\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn = knn.fit(x_data, y_data)\n",
    "    y_pred = knn.predict(x_data)\n",
    "    score = accuracy(y_data, y_pred)\n",
    "    score_list.append((k, score))\n",
    "\n",
    "score_data = pd.DataFrame(score_list, columns=['k', 'accuracy'])\n",
    "sns.set_context('talk')\n",
    "sns.set_style('ticks')\n",
    "sns.set_palette('dark')\n",
    "ax = score_data.set_index('k').plot()\n",
    "ax.set(xlabel='k', ylabel='accuracy')\n",
    "ax.set_xticks(range(1, 21));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4840a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63853476",
   "metadata": {},
   "source": [
    "**Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c89665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unused column\n",
    "data_new=data_new.drop(columns=['date'])\n",
    "\n",
    "#Define training and testing data\n",
    "x_cols = [x for x in data_new.columns]\n",
    "x_data = data_new[x_cols]\n",
    "\n",
    "y_col = 'cases_active'\n",
    "\n",
    "x_cols = [x for x in data_new.columns if x != y_col]\n",
    "X_data = data_new[x_cols]\n",
    "y_data = data_new[y_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330810ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR fit\n",
    "lr=LinearRegression()\n",
    "\n",
    "lr=lr.fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "#Calculate mean square error\n",
    "mse_train=mean_squared_error(y_train, y_train_pred)\n",
    "mse_test=mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(mse_train,mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1594cbb",
   "metadata": {},
   "source": [
    "**LR with scaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ef1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "scalers = {'Standard': StandardScaler(),\n",
    "'Minmax': MinMaxScaler(),\n",
    "'Maxabs': MaxAbsScaler()}\n",
    "\n",
    "predList=[]\n",
    "for label,scaler in scalers.items():\n",
    "    trainingset=X_train.copy()\n",
    "    testset = X_test.copy()\n",
    "    trainingset[x_cols]=scaler.fit_transform(trainingset[x_cols])\n",
    "    testset[x_cols] = scaler.fit_transform(testset[x_cols])\n",
    "\n",
    "    lr.fit(trainingset, y_train)\n",
    "    \n",
    "    test_pred = lr.predict(testset)\n",
    "    predList.append(test_pred)\n",
    "    \n",
    "    mse=mean_squared_error(y_test, test_pred)\n",
    "\n",
    "    print(label,\"Scaler - \",mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bec71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot predictions\n",
    "ax = plt.axes()\n",
    "ax.plot(y_test,y_test,c=\"black\",alpha=0.5)\n",
    "ax.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "ax.scatter(y_test, predList[0], alpha=0.5,c=\"red\")\n",
    "ax.scatter(y_test, predList[1], alpha=0.5,c=\"yellow\")\n",
    "ax.scatter(y_test, predList[2], alpha=0.5,c=\"green\")\n",
    "\n",
    "ax.set(xlabel='Ground truth',\n",
    "ylabel='Predictions',\n",
    "title='Linear Regression');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3046db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot best fit line\n",
    "ax = plt.subplot(221)\n",
    "ax.axes.xaxis.set_ticklabels([])\n",
    "ax.axes.yaxis.set_ticklabels([])\n",
    "#ax2 = plt.subplot(222)\n",
    "#ax3 = plt.subplot(223)\n",
    "#ax4 = plt.subplot(224)\n",
    "#ax = plt.axes()\n",
    "x = y_test\n",
    "\n",
    "ax.plot(x, x,c=\"black\",alpha=0.3) \n",
    "\n",
    "a, b = np.polyfit(x, y_test_pred, 1)\n",
    "ax.plot(x, a*x+b,c=\"red\",alpha=0.5)\n",
    "ax.title.set_text('No scaler')\n",
    "\n",
    "i=0\n",
    "for label,scaler in scalers.items():\n",
    "    ax = plt.subplot(222+i)\n",
    "    ax.axes.xaxis.set_ticklabels([])\n",
    "    ax.axes.yaxis.set_ticklabels([])\n",
    "    \n",
    "    a, b = np.polyfit(x, predList[i], 1)\n",
    "    ax.plot(x, x,c=\"black\",alpha=0.3) \n",
    "    ax.plot(x, a*x+b,c=\"red\",alpha=0.5)\n",
    "    ax.title.set_text(label)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d6af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define test function\n",
    "def LRTest(data,target):\n",
    "    x_cols = [x for x in data.columns]\n",
    "    x_data = data[x_cols]\n",
    "    mseList=[]\n",
    "\n",
    "    y_col = target\n",
    "\n",
    "    x_cols = [x for x in data.columns if x != y_col]\n",
    "    X_data = data[x_cols]\n",
    "    y_data = data[y_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data,test_size=0.2)\n",
    "    \n",
    "    lr=LinearRegression()\n",
    "\n",
    "    lr=lr.fit(X_train,y_train)\n",
    "    \n",
    "    y_train_pred = lr.predict(X_train)\n",
    "    y_test_pred = lr.predict(X_test)\n",
    "\n",
    "    mse_train=mean_squared_error(y_train, y_train_pred)\n",
    "    mse_test=mean_squared_error(y_test, y_test_pred)\n",
    "    \n",
    "    mseList.append(mse_test)\n",
    "    \n",
    "    #With Scaler\n",
    "    \n",
    "    scalers = {'Standard': StandardScaler(),\n",
    "    'Minmax': MinMaxScaler(),\n",
    "    'Maxabs': MaxAbsScaler()}\n",
    "    \n",
    "    predList=[]\n",
    "    for label,scaler in scalers.items():\n",
    "        trainingset=X_train.copy()\n",
    "        testset = X_test.copy()\n",
    "        trainingset[x_cols]=scaler.fit_transform(trainingset[x_cols])\n",
    "        testset[x_cols] = scaler.fit_transform(testset[x_cols])\n",
    "\n",
    "        lr.fit(trainingset, y_train)\n",
    "\n",
    "        test_pred = lr.predict(testset)\n",
    "        predList.append(test_pred)\n",
    "\n",
    "        mse=mean_squared_error(y_test, test_pred)\n",
    "        mseList.append(mse)\n",
    "        \n",
    "    return mseList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd873a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsTotal=0\n",
    "stdTotal=0\n",
    "mmTotal=0\n",
    "maTotal=0\n",
    "\n",
    "for i in range (100):\n",
    "    print(\"Test \",i+1)\n",
    "    mseList=LRTest(data_new,'cases_active')\n",
    "    print(\"MSE for no scaling\",mseList[0])\n",
    "    print(\"MSE for Standard scaling\",mseList[1])\n",
    "    print(\"MSE for Minmax scaling\",mseList[2])\n",
    "    print(\"MSE for Maxabs scaling\",mseList[3])\n",
    "    \n",
    "    nsTotal+=mseList[0]\n",
    "    stdTotal+=mseList[1]\n",
    "    mmTotal+=mseList[2]\n",
    "    maTotal+=mseList[3]\n",
    "    \n",
    "print(\"Average MSE for no scaling: \",nsTotal/i)\n",
    "print(\"Average MSE for Standard scaling: \",stdTotal/i)\n",
    "print(\"Average MSE for Minmax scaling: \",mmTotal/i)\n",
    "print(\"Average MSE for Maxabs scaling: \",maTotal/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6161e0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
